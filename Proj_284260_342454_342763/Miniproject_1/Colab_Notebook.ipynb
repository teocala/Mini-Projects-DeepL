{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import auth\n","auth.authenticate_user()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2-0sGH4Ti3D","executionInfo":{"status":"ok","timestamp":1649843173889,"user_tz":-120,"elapsed":24575,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}},"outputId":"238adec3-eca2-415f-fdd6-8b95820d66a3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["my_path = '/content/drive/MyDrive/DeepL/Miniproject_1/'"],"metadata":{"id":"9A2Vit1lTvNe","executionInfo":{"status":"ok","timestamp":1649843198254,"user_tz":-120,"elapsed":204,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"no978ZHTSaNa","executionInfo":{"status":"ok","timestamp":1649843179759,"user_tz":-120,"elapsed":5559,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"outputs":[],"source":["import torch \n","from torch import nn"]},{"cell_type":"code","source":["def psnr(denoised, ground_truth):\n","    # Peak Signal to Noise Ratio : denoised and ground˙truth have range [0 , 1]\n","    mse = torch . mean ((denoised - ground_truth ) ** 2)\n","    return -10 * torch . log10 ( mse + 10** -8)"],"metadata":{"id":"skiuQ9RGT7sf","executionInfo":{"status":"ok","timestamp":1649843179759,"user_tz":-120,"elapsed":12,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["### For mini-project 1\n","class Model(nn.Module):\n","    def __init__(self) -> None:\n","        ## instantiate model + optimizer + loss function + any other stuff you need\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size = 5, stride = 1),  # N , 32, 28 , 28\n","            nn.ReLU(),\n","            nn.Conv2d(32,32,kernel_size=5,stride = 1, padding = 2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2), # N , 32 , 14 , 14\n","            nn.Conv2d(32,64, kernel_size = 5, stride = 1, padding = 2), # N , 64, 10, 10\n","            nn.ReLU(),\n","            nn.Conv2d(64,64,kernel_size=5,stride=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2 , stride = 2), # N , 64 , 5 , 5\n","            nn.Conv2d(64,128, kernel_size = 5, stride = 1) # N , 128 , 1 , 1\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(128,64, kernel_size = 5, stride = 1), # N, 64, 5, 5\n","            nn.Upsample(scale_factor=2, mode = 'bilinear', align_corners=True), # N , 64, 10, 10\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64,64,kernel_size=5,stride=1, padding = 2), # N, 64, 10, 10\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64,32,kernel_size=5,stride=1), # N , 32, 14, 14\n","            nn.Upsample(scale_factor=2,mode = 'bilinear', align_corners=True), # N, 32, 28, 28\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32,32,kernel_size=5,stride=1, padding=2), # N, 32, 28, 28\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32,3,kernel_size=5,stride=1) # N, 3, 32, 32\n","        )\n","\n","        self.criterion = nn.MSELoss()\n","        self.optimizer = torch.optim.Adam(self.parameters(), lr = 0.001)\n","        \n","\n","    def load_pretrained_model(self ) -> None:\n","        ## This loads the parameters saved in bestmodel . pth into the model\n","        pass\n","\n","    def train(self, train_input, train_target) -> None:\n","        # : train˙input : tensor of size (N , C , H , W ) containing a noisy version of the images.\n","        # : train˙target : tensor of size (N , C , H , W ) containing another noisy version of the\n","        # same images , which only differs from the input by their noise.\n","\n","        batch_size = 100\n","        epochs = 500\n","        total_loss = 0\n","\n","        for epoch in range(epochs):\n","            print(f'Epoch {epoch}/{epochs-1} Training Loss {total_loss}')\n","            total_loss = 0\n","            for batch_input, batch_target in zip(train_input.split(batch_size), train_target.split(batch_size)):\n","                output = self.predict(batch_input)\n","                loss = self.criterion(output, batch_target)\n","                total_loss += loss\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","    \n","    def predict(self, test_input) -> torch.Tensor:\n","        # : test˙input : tensor of size ( N1 , C , H , W ) that has to be denoised by the trained\n","        # or the loaded network .\n","        # : returns a tensor of the size ( N1 , C , H , W )\n","        \n","        # like the forward method\n","        \n","        y = self.encoder(test_input)\n","        y = self.decoder(y)\n","        \n","        return y\n"],"metadata":{"id":"wrpou9NqSqvm","executionInfo":{"status":"ok","timestamp":1649843179759,"user_tz":-120,"elapsed":9,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def main():\n","\n","    device = torch.device('cuda')\n","\n","    # Load the data    \n","    print('Loading the data...')\n","    train_input, train_target = torch.load(my_path + 'train_data.pkl')\n","    test_input, test_target = torch.load(my_path + 'val_data.pkl')\n","    train_input, train_target = train_input.to(device), train_target.to(device)\n","    test_input, test_target = test_input.to(device), test_target.to(device)\n","\n","\n","    # Select a subset to speed up computations\n","    train_size = 1000\n","    train_input = train_input[:train_size]\n","    train_target = train_target[:train_size]\n","    test_input = test_input[:train_size]\n","    test_target = test_target[:train_size]\n","\n","\n","    # Convert the data into float type\n","    train_input = train_input.float()\n","    train_target = train_target.float()\n","    test_input = test_input.float()\n","    test_target = test_target.float()\n","\n","    \n","    print(f'Training data of size {train_input.shape}')\n","\n","    # Defining and training the model\n","    model = Model()\n","    model = model.to(device)\n","    print('Training the model...')\n","    model.train(train_input, train_target)\n","\n","    # Testing\n","    print('Using the trained model to denoise validation images...')\n","    with torch.no_grad():\n","        prediction = model.predict(test_input)\n","\n","    # Evaluating error\n","    error = psnr(prediction, test_target)\n","    print(f'The PSNR on the validation set is {error} DB')"],"metadata":{"id":"LYPefORASvQ-","executionInfo":{"status":"ok","timestamp":1649843303798,"user_tz":-120,"elapsed":252,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ROWodlRdUCcl","executionInfo":{"status":"error","timestamp":1649843338853,"user_tz":-120,"elapsed":34875,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}},"outputId":"187b8101-402e-4ee9-d8c1-7b0af55c6162"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading the data...\n","Training data of size torch.Size([1000, 3, 32, 32])\n","Training the model...\n","Epoch 0/499 Training Loss 0\n","Epoch 1/499 Training Loss 163230.296875\n","Epoch 2/499 Training Loss 143448.984375\n","Epoch 3/499 Training Loss 89303.59375\n","Epoch 4/499 Training Loss 69913.1875\n","Epoch 5/499 Training Loss 58672.859375\n","Epoch 6/499 Training Loss 50199.37890625\n","Epoch 7/499 Training Loss 45319.0\n","Epoch 8/499 Training Loss 41292.1328125\n","Epoch 9/499 Training Loss 38351.53125\n","Epoch 10/499 Training Loss 36208.9375\n","Epoch 11/499 Training Loss 34502.20703125\n","Epoch 12/499 Training Loss 33538.140625\n","Epoch 13/499 Training Loss 32948.7421875\n","Epoch 14/499 Training Loss 32371.7109375\n","Epoch 15/499 Training Loss 32120.2578125\n","Epoch 16/499 Training Loss 36821.14453125\n","Epoch 17/499 Training Loss 34216.2890625\n","Epoch 18/499 Training Loss 30961.90234375\n","Epoch 19/499 Training Loss 29223.736328125\n","Epoch 20/499 Training Loss 28241.814453125\n","Epoch 21/499 Training Loss 27732.037109375\n","Epoch 22/499 Training Loss 27435.142578125\n","Epoch 23/499 Training Loss 27154.619140625\n","Epoch 24/499 Training Loss 26856.76953125\n","Epoch 25/499 Training Loss 26583.669921875\n","Epoch 26/499 Training Loss 26255.830078125\n","Epoch 27/499 Training Loss 25953.212890625\n","Epoch 28/499 Training Loss 25721.873046875\n","Epoch 29/499 Training Loss 25384.4296875\n","Epoch 30/499 Training Loss 25077.2421875\n","Epoch 31/499 Training Loss 24903.806640625\n","Epoch 32/499 Training Loss 24729.943359375\n","Epoch 33/499 Training Loss 24514.46875\n","Epoch 34/499 Training Loss 24481.185546875\n","Epoch 35/499 Training Loss 24359.41796875\n","Epoch 36/499 Training Loss 24124.33203125\n","Epoch 37/499 Training Loss 23933.91796875\n","Epoch 38/499 Training Loss 23687.24609375\n","Epoch 39/499 Training Loss 24299.583984375\n","Epoch 40/499 Training Loss 26405.6015625\n","Epoch 41/499 Training Loss 24663.33203125\n","Epoch 42/499 Training Loss 23923.107421875\n","Epoch 43/499 Training Loss 23591.38671875\n","Epoch 44/499 Training Loss 23197.11328125\n","Epoch 45/499 Training Loss 22844.693359375\n","Epoch 46/499 Training Loss 22604.109375\n","Epoch 47/499 Training Loss 22466.6953125\n","Epoch 48/499 Training Loss 22378.87109375\n","Epoch 49/499 Training Loss 22280.251953125\n","Epoch 50/499 Training Loss 22211.265625\n","Epoch 51/499 Training Loss 22143.625\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-e9270a7da08a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training the model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-47f0dbff3a32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_input, train_target)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}/{epochs-1} Training Loss {total_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"wx2oOcaJUEJF","executionInfo":{"status":"aborted","timestamp":1649843180095,"user_tz":-120,"elapsed":5,"user":{"displayName":"Thomas Rimbot","userId":"15888538818063873745"}}},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"name":"Colab_Notebook.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}